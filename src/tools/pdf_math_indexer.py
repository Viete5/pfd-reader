import os
import logging
import hashlib
import re
import shutil
import pdfplumber
from typing import Optional, List

logger = logging.getLogger(__name__)

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
CACHE_DIR = os.path.join(os.getcwd(), "marker_cache")
PDF_CACHE_DIR = os.path.join(os.getcwd(), "pdf_cache")
VECTOR_DB_ROOT_PATH = os.path.join(os.getcwd(), "vector_db")  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏

os.makedirs(CACHE_DIR, exist_ok=True)
os.makedirs(PDF_CACHE_DIR, exist_ok=True)

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ Marker
try:
    from marker.converters.pdf import PdfConverter
    from marker.models import create_model_dict
    from marker.output import text_from_rendered

    MARKER_AVAILABLE = True
except ImportError:
    MARKER_AVAILABLE = False
    logger.warning("‚ö†Ô∏è Marker-pdf –Ω–µ –Ω–∞–π–¥–µ–Ω. –ö–∞—á–µ—Å—Ç–≤–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö —Ñ–æ—Ä–º—É–ª –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–Ω–∏–∂–µ–Ω–æ.")

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ Embeddings (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
try:
    from langchain_huggingface import HuggingFaceEmbeddings

    EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
except ImportError:
    HuggingFaceEmbeddings = None

_MARKER_MODELS = None


def load_marker_models():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª–∏ Marker –æ–¥–∏–Ω —Ä–∞–∑ –≤ –ø–∞–º—è—Ç—å."""
    global _MARKER_MODELS
    if _MARKER_MODELS is None and MARKER_AVAILABLE:
        logger.info("üì• [Marker] –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π... (–ú–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)")
        _MARKER_MODELS = create_model_dict()
    return _MARKER_MODELS


# --- –ì–ï–û–ú–ï–¢–†–ò–ß–ï–°–ö–ò–ô –ü–ê–†–°–ï–† (–ü–ª–∞–Ω –ë) ---
def parse_pdf_geometrically(file_path: str) -> str:
    """
    –ü–∞—Ä—Å–∏—Ç PDF, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö —Å–ª–æ–≤.
    –ü—ã—Ç–∞–µ—Ç—Å—è "—Å–∫–ª–µ–∏—Ç—å" –¥—Ä–æ–±–∏, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã–µ –¥—Ä—É–≥ –Ω–∞–¥ –¥—Ä—É–≥–æ–º.
    """
    logger.info("üìê –ó–∞–ø—É—Å–∫ –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ (Fallback)...")
    full_text = []
    try:
        with pdfplumber.open(file_path) as pdf:
            for p_num, page in enumerate(pdf.pages):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
                words = page.extract_words(keep_blank_chars=True, x_tolerance=2, y_tolerance=3)

                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–ª–æ–≤–∞ –≤ —Å—Ç—Ä–æ–∫–∏ –ø–æ Y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–µ (—Å –¥–æ–ø—É—Å–∫–æ–º 8 –ø–∏–∫—Å–µ–ª–µ–π)
                lines_map = {}
                for w in words:
                    y_key = int(w['top'] // 8) * 8
                    if y_key not in lines_map: lines_map[y_key] = []
                    lines_map[y_key].append(w)

                sorted_ys = sorted(lines_map.keys())
                processed_lines = []
                skip_y_indices = set()

                for i, y in enumerate(sorted_ys):
                    if i in skip_y_indices: continue

                    row = sorted(lines_map[y], key=lambda x: x['x0'])
                    row_text = " ".join([w['text'] for w in row])

                    # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–æ–∫–∏
                    row_left = row[0]['x0']
                    row_right = row[-1]['x1']

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—Ä–æ–±—å (–µ—Å—Ç—å –ª–∏ —Å—Ç—Ä–æ–∫–∞ –ø—Ä—è–º–æ –ø–æ–¥ —ç—Ç–æ–π?)
                    is_fraction = False
                    if i + 1 < len(sorted_ys):
                        next_y = sorted_ys[i + 1]
                        # –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–æ–∫–∞ –æ—á–µ–Ω—å –±–ª–∏–∑–∫–æ (–º–µ–Ω—å—à–µ 18 –ø–∏–∫—Å–µ–ª–µ–π)
                        if (next_y - y) < 18:
                            next_row = sorted(lines_map[next_y], key=lambda x: x['x0'])
                            next_text = " ".join([w['text'] for w in next_row])

                            next_left = next_row[0]['x0']
                            next_right = next_row[-1]['x1']

                            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏
                            overlap = min(row_right, next_right) - max(row_left, next_left)
                            if overlap > 5:  # –ï—Å–ª–∏ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ
                                combined = f"({row_text}) / ({next_text})"
                                processed_lines.append(combined)
                                skip_y_indices.add(i + 1)  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–æ–∫—É, —Ç–∞–∫ –∫–∞–∫ –æ–±—ä–µ–¥–∏–Ω–∏–ª–∏
                                is_fraction = True

                    if not is_fraction:
                        processed_lines.append(row_text)

                # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç —è–≤–Ω–æ–≥–æ –º—É—Å–æ—Ä–∞ (–µ—Å–ª–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞ —Å–æ–≤—Å–µ–º –±–∏—Ç–∞—è)
                clean_lines = []
                for line in processed_lines:
                    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ü–∏—Ñ—Ä—ã, –±—É–∫–≤—ã, –º–∞—Ç. —Å–∏–º–≤–æ–ª—ã
                    if len(line.strip()) > 1:
                        clean_lines.append(line)

                full_text.append(f"--- Page {p_num + 1} ---\n" + "\n".join(clean_lines))
        return "\n".join(full_text)
    except Exception as e:
        logger.error(f"Fallback Parser Error: {e}")
        return "Error parsing PDF geometrically."


# --- –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ---
def extract_math_context_ultimate(file_path: str, force_refresh: bool = False) -> str:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ PDF.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Marker (–µ—Å–ª–∏ –µ—Å—Ç—å) –∏–ª–∏ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–µ—Ä.
    """
    file_hash = hashlib.md5(file_path.encode()).hexdigest()
    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ ID, —á—Ç–æ–±—ã –æ—Ç–ª–∏—á–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Ñ–∞–π–ª—ã —Å –æ–¥–Ω–∏–º –∏–º–µ–Ω–µ–º
    file_size = os.path.getsize(file_path)
    filename = os.path.basename(file_path).replace(".pdf", "")

    cache_path = os.path.join(CACHE_DIR, f"{filename}_{file_hash}_{file_size}.md")

    # 1. –ï—Å–ª–∏ –Ω–µ –ø—Ä–æ—Å–∏–ª–∏ –æ–±–Ω–æ–≤–∏—Ç—å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ - —á–∏—Ç–∞–µ–º –∫–µ—à
    if os.path.exists(cache_path) and not force_refresh:
        logger.info(f"üìñ –ß–∏—Ç–∞—é –∏–∑ –∫–µ—à–∞: {cache_path}")
        with open(cache_path, "r", encoding="utf-8") as f:
            return f.read()

    text_result = ""
    # 2. –ü–æ–ø—ã—Ç–∫–∞ Marker
    if MARKER_AVAILABLE:
        logger.info(f"‚öôÔ∏è [Marker] –ó–∞–ø—É—Å–∫ OCR –¥–ª—è {filename}...")
        try:
            model_dict = load_marker_models()
            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π Marker (—á–µ—Ä–µ–∑ —Å–ª–æ–≤–∞—Ä—å)
            config_dict = {
                "output_format": "markdown",
                "force_ocr": True,  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π OCR –¥–ª—è –±–∏—Ç—ã—Ö PDF
                "languages": ["ru", "en"]
            }

            converter = PdfConverter(artifact_dict=model_dict, config=config_dict)
            rendered = converter(file_path)
            text_result, _, _ = text_from_rendered(rendered)
            logger.info("‚úÖ Marker —É—Å–ø–µ—à–Ω–æ –æ—Ç—Ä–∞–±–æ—Ç–∞–ª!")
        except Exception as e:
            logger.error(f"‚ö†Ô∏è Marker —É–ø–∞–ª: {e}")
            logger.warning("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–µ—Ä...")
            text_result = parse_pdf_geometrically(file_path)
    else:
        text_result = parse_pdf_geometrically(file_path)

    # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    if text_result:
        # –ï—Å–ª–∏ –æ–±–Ω–æ–≤–ª—è–ª–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ - —É–¥–∞–ª–∏–º —Å—Ç–∞—Ä—ã–µ –∫–µ—à–∏ —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
        if force_refresh:
            for f in os.listdir(CACHE_DIR):
                if f.startswith(filename) and f != os.path.basename(cache_path):
                    try:
                        os.remove(os.path.join(CACHE_DIR, f))
                    except:
                        pass
        with open(cache_path, "w", encoding="utf-8") as f:
            f.write(text_result)

    return text_result


# --- –§–£–ù–ö–¶–ò–ò –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò (–¥–ª—è orchestrator.py) ---
def index_user_pdf(file_path: str, user_id: int) -> bool:
    """
    –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞.
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª –∏ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û –æ–±–Ω–æ–≤–ª—è–µ—Ç –∏–Ω–¥–µ–∫—Å.
    """
    try:
        # 1. –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ —ç—Ç–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        # (–ú—ã —Ö—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ 1 –∞–∫—Ç–∏–≤–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á, —á—Ç–æ–±—ã –Ω–µ –ø—É—Ç–∞—Ç—å—Å—è)
        for f in os.listdir(PDF_CACHE_DIR):
            if f.startswith(f"user_{user_id}"):
                try:
                    os.remove(os.path.join(PDF_CACHE_DIR, f))
                except:
                    pass

        # 2. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
        dest_path = os.path.join(PDF_CACHE_DIR, f"user_{user_id}.pdf")
        shutil.copy(file_path, dest_path)
        logger.info(f"üìÑ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {dest_path}")

        # 3. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ (Progress Bar –≤ –ª–æ–≥–∞—Ö)
        logger.info(f"üî• –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ñ–∞–π–ª–∞ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 10-40 —Å–µ–∫)...")
        extract_math_context_ultimate(dest_path, force_refresh=True)

        return True
    except Exception as e:
        logger.error(f"Index Error: {e}", exc_info=True)
        return False


def get_user_db_path(user_id: int) -> str:
    """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –ø—É—Ç–µ–π"""
    return os.path.join(VECTOR_DB_ROOT_PATH, f"user_{user_id}")


def get_embeddings():
    """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
    if HuggingFaceEmbeddings:
        return HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
    return None
